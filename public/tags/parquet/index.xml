<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>parquet on 一个程序员的博客</title>
    <link>https://hehe-1234.xyz/tags/parquet/</link>
    <description>Recent content in parquet on 一个程序员的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 02 Oct 2024 09:08:07 +0800</lastBuildDate><atom:link href="https://hehe-1234.xyz/tags/parquet/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Parquet for Spark</title>
      <link>https://hehe-1234.xyz/post/2024/10/parquet_4_spark/</link>
      <pubDate>Wed, 02 Oct 2024 09:08:07 +0800</pubDate>
      
      <guid>https://hehe-1234.xyz/post/2024/10/parquet_4_spark/</guid>
      <description>Spark执行Delta的过程，通过自定义的format格式，到DataFrameWriter.saveToV1Source，在是到DeltaDataSource#createRealation，写入做优化事务处理，再用FileFormatWriter创建多个Task并行写入，之后就是到Parquet内部执行阶段。Parquet包含Row Groups，往下是Column Chunk，再往下是Page，文件尾部包含Footer和一些元数据信息。Spark是按行写入的，一次写一行，每行写对应的 column。Parquet编码包括Dictionary Encoding、Run Length Encoding (RLE)、Delta Encoding。读取的主要类是VectorizedParquetRecordReader执行一批读取，调用VectorizedColumnReaders(对应每个column)，再调用VectorizedValuesReader(读取一个column中的一段数据)，返回由上层应用消费 。</description>
    </item>
    
  </channel>
</rss>
